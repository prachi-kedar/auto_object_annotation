{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple object tracking with YOLOv3-based object detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from motrackers.detectors import YOLOv3\n",
    "from motrackers import CentroidTracker, CentroidKF_Tracker, SORT, IOUTracker\n",
    "from motrackers.utils import draw_tracks\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_FILE = \"./../video_data/cars.mp4\"\n",
    "WEIGHTS_PATH = './../pretrained_models/yolo_weights/yolov3.weights'\n",
    "CONFIG_FILE_PATH = './../pretrained_models/yolo_weights/yolov3.cfg'\n",
    "LABELS_PATH = \"./../pretrained_models/yolo_weights/coco_names.json\"\n",
    "\n",
    "CONFIDENCE_THRESHOLD = 0.5\n",
    "NMS_THRESHOLD = 0.2\n",
    "DRAW_BOUNDING_BOXES = True\n",
    "USE_GPU = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91158609370f49aaa990546bc851a309",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Select(description='MOTracker:', options=('CentroidTracker', 'CentroidKF_Tracker', 'SORT', 'IOUTracker'), valuâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chosen_tracker = widgets.Select(\n",
    "    options=[\"CentroidTracker\", \"CentroidKF_Tracker\", \"SORT\", \"IOUTracker\"],\n",
    "    value='CentroidTracker',\n",
    "    rows=5,\n",
    "    description='MOTracker:',\n",
    "    disabled=False\n",
    ")\n",
    "chosen_tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if chosen_tracker.value == 'CentroidTracker':\n",
    "    tracker = CentroidTracker(max_lost=0, tracker_output_format='mot_challenge')\n",
    "elif chosen_tracker.value == 'CentroidKF_Tracker':\n",
    "    tracker = CentroidKF_Tracker(max_lost=0, tracker_output_format='mot_challenge')\n",
    "elif chosen_tracker.value == 'SORT':\n",
    "    tracker = SORT(max_lost=3, tracker_output_format='mot_challenge', iou_threshold=0.3)\n",
    "elif chosen_tracker.value == 'IOUTracker':\n",
    "    tracker = IOUTracker(max_lost=2, iou_threshold=0.5, min_detection_confidence=0.4, max_detection_confidence=0.7,\n",
    "                         tracker_output_format='mot_challenge')\n",
    "else:\n",
    "    print(\"Please choose one tracker from the above list.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLOv3(\n",
    "    weights_path=WEIGHTS_PATH,\n",
    "    configfile_path=CONFIG_FILE_PATH,\n",
    "    labels_path=LABELS_PATH,\n",
    "    confidence_threshold=CONFIDENCE_THRESHOLD,\n",
    "    nms_threshold=NMS_THRESHOLD,\n",
    "    draw_bboxes=DRAW_BOUNDING_BOXES,\n",
    "    use_gpu=USE_GPU\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def main(video_path, model, tracker):\n",
    "\n",
    "    cap = cv.VideoCapture(0)\n",
    "    while True:\n",
    "        ok, image = cap.read()\n",
    "\n",
    "        if not ok:\n",
    "            print(\"Cannot read the video feed.\")\n",
    "            break\n",
    "\n",
    "        image = cv.resize(image, (700, 500))\n",
    "\n",
    "        bboxes, confidences, class_ids = model.detect(image)\n",
    "        print(bboxes)\n",
    "        \n",
    "        tracks = tracker.update(bboxes, confidences, class_ids)\n",
    "        \n",
    "        updated_image = model.draw_bboxes(image.copy(), bboxes, confidences, class_ids)\n",
    "\n",
    "        updated_image = draw_tracks(updated_image, tracks)\n",
    "\n",
    "        cv.imshow(\"image\", updated_image)\n",
    "        if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -2  18 267 461]]\n",
      "[[  0  13 269 468]]\n",
      "[[  4  15 268 463]]\n",
      "[[  5  13 268 467]]\n",
      "[[  7   9 269 475]]\n",
      "[[ -1  -4 246 494]\n",
      " [248 315 432 185]]\n",
      "[[  9   4 211 489]\n",
      " [254 315 426 185]]\n",
      "[[ -5   8 322 482]]\n",
      "[[  0   6 262 482]]\n",
      "[[ -5  10 368 472]]\n",
      "[[-10  15 378 468]]\n",
      "[[ -2  18 304 457]]\n",
      "[[ -3  12 352 471]\n",
      " [249 318 433 180]]\n",
      "[[ -6   5 386 470]\n",
      " [244 320 439 176]]\n",
      "[[ -3  -3 399 492]\n",
      " [246 317 435 181]]\n",
      "[[ -7  -7 400 505]\n",
      " [246 316 439 182]]\n",
      "[[ -9  -4 402 495]\n",
      " [244 317 437 181]]\n",
      "[[ -8  -5 397 500]\n",
      " [249 317 432 181]]\n",
      "[[ -5  -4 397 500]\n",
      " [245 318 435 180]]\n",
      "[[ -5  -6 399 504]\n",
      " [246 316 435 183]]\n",
      "[[ -4  -7 402 506]\n",
      " [244 316 439 183]]\n",
      "[[-10  -8 399 502]\n",
      " [247 317 436 181]]\n",
      "[[ -6  -1 369 492]\n",
      " [248 319 435 180]]\n",
      "[[  4  15 285 459]]\n",
      "[[  3   1 232 493]\n",
      " [249 317 430 183]]\n",
      "[[  0   4 129 483]\n",
      " [249 315 436 185]]\n",
      "[[  0  11  66 490]]\n",
      "[[  0  35  62 485]\n",
      " [244 314 443 186]]\n",
      "[[  0   0  71 515]]\n",
      "[[  0  57  90 405]]\n",
      "[[  0  93  74 410]]\n",
      "[[  0  87  70 421]]\n",
      "[[  1  89  69 418]]\n",
      "[[  0  78  72 402]]\n",
      "[[  0  78  75 400]\n",
      " [246 313 437 187]]\n",
      "[[  0  84  78 350]\n",
      " [244 315 442 185]]\n",
      "[[244 317 443 183]]\n",
      "[[250 315 434 187]]\n",
      "[[249 317 436 183]]\n",
      "[[249 316 437 185]]\n",
      "[[249 315 438 185]]\n",
      "[[246 315 442 185]]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'flatten'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-22a719c81d8c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVIDEO_FILE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-538d3eca9474>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(video_path, model, tracker)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m700\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mbboxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfidences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbboxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/omkar/omkar3/object_tracker/multi-object-tracker/motrackers/detectors/yolo.py\u001b[0m in \u001b[0;36mdetect\u001b[0;34m(self, image)\u001b[0m\n\u001b[1;32m     62\u001b[0m                     \u001b[0mclass_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNMSBoxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbboxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfidences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfidence_threshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnms_threshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0mclass_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'int'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbboxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'int'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfidences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'flatten'"
     ]
    }
   ],
   "source": [
    "main(VIDEO_FILE, model, tracker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openvino",
   "language": "python",
   "name": "openvino"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
